apiVersion: v1
kind: ConfigMap
metadata:
  name: librechat-config
  labels: { app: llama, component: librechat }
data:
  librechat.yaml: |
    version: 1.2.8
    cache: true
    endpoints:
      custom:
        - name: "LlamaCPP"
          apiKey: "user_provided"
          baseURL: "https://llama-api.rcrumana.xyz/v1"
          models:
            default: ["local-gguf"]
            fetch: false
          titleConvo: true
          titleModel: "current_model"
          summarize: false
          summaryModel: "current_model"
          forcePrompt: false
          modelDisplayLabel: "Llama.cpp"
    interface:
      defaultEndpoint: "LlamaCPP"
      defaultModel: "local-gguf"