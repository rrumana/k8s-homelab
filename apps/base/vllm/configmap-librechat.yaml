apiVersion: v1
kind: ConfigMap
metadata:
  name: librechat-config
  labels: { app: vllm, component: librechat }
data:
  librechat.yaml: |
    version: 1.2.9
    cache: true
    endpoints:
      custom:
        - name: "vLLM"
          apiKey: "${VLLM_API_KEY}"
          baseURL: "https://vllm-api.rcrumana.xyz/v1"
          models:
            default: ["meta-llama-3-8b-instruct"]
            fetch: true
          titleConvo: true
          titleModel: "meta-llama-3-8b-instruct"
          summarize: false
          forcePrompt: false
          modelDisplayLabel: "vLLM"
    interface:
      defaultEndpoint: "vLLM"
      defaultModel: "meta-llama-3-8b-instruct"
      modelSelect: true
